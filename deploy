#!/bin/bash

set -e

env="$1"
pagegen='/home/oliver/Personal/projects/pagegen/v2/pagegen'
site_dir='/home/oliver/Personal/projects/pagegen/pagegenv2_site/site'
prod_url="http://pagegen.phnd.net"
stage_url="http://pagegen.phnd.net"
prod_conf='/home/oliver/Personal/projects/pagegen/pagegenv2_site/prod_site.conf'
stage_conf='/home/oliver/Personal/projects/pagegen/pagegenv2_site/stage_site.conf'
test_conf='/home/oliver/Personal/projects/pagegen/pagegenv2_site/test_site.conf'



if [ "$env" = "prod" ] || [ "$env" = "stage" ]; then

  if [ "$env" = "prod" ]; then
    conf="$prod_conf"
    url="$prod_url"
  else
    conf="$stage_conf"
    url="$stage_url"
  fi

  $pagegen --generate --config "$conf"

  source "${env}_ftp.conf"

  # Gzip seperate html, css and javascript files, that way can serve both gzip and regular files

  echo "Only return files over certain size, compressing small files is stupid"

  # Rename html files with .html
  find "$site_dir" -type f -regex '^[^\.]*$' -exec mv {} {}.html \;

  # Create compressed copies of files that are larger than 1.4Kb
  #find "$site_dir" -type f -size +1400c \( -name '*.html' -o -name '*.txt' -o -name '*.css' -o -name '*.js' \) -exec gzip --best {} \;
  find "$site_dir" -type f -size +1400c \( -name '*.html' -o -name '*.txt' -o -name '*.css' -o -name '*.js' \) \
  | sed 's/.*/gzip --best -c "&" > "&.gz"/' \
  | sh

#  tree "$site_dir"

  # Add prod .htaccess
  # Inspiration gzip content
  # http://stackoverflow.com/questions/16883241/how-to-host-static-content-pre-compressed-in-apache
  echo '
AddEncoding x-gzip .gz
AddCharset UTF-8 *

ErrorDocument 404 /404.html

ExpiresActive On
ExpiresDefault "access plus 60 seconds"
ExpiresByType text/html "access plus 60 seconds"
ExpiresByType image/x-icon "access plus 2592000 seconds"
ExpiresByType image/gif "access plus 2592000 seconds"
ExpiresByType image/jpeg "access plus 2592000 seconds"
ExpiresByType image/png "access plus 2592000 seconds"
ExpiresByType text/css "access plus 604800 seconds"
ExpiresByType text/javascript "access plus 86400 seconds"
ExpiresByType application/javascript "access plus 86400 seconds"

<files *.css.gz>
ForceType text/css
</files>
<files *.js.gz>
ForceType application/javascript
</files>
<files *.txt.gz>
ForceType text/plain
</files>
<files *.html.gz>
ForceType text/html
</files>

<IfModule mod_rewrite.c>
  RewriteEngine on 

  # Old pagegen v0.8 site redirects
  Redirect 301 /contact/default /
  Redirect 301 /default /
  Redirect 301 /download/default /download
  Redirect 301 /examples/content-formating /user-manual/content-management
  Redirect 301 /examples/content-variables /user-manual/content-management
  Redirect 301 /examples/custom-meta-description-tag /user-manual/design-and-layout
  Redirect 301 /examples/custom-page-title-tag /user-manual/design-and-layout
  Redirect 301 /examples/default /
  Redirect 301 /examples/dynamic-content-page /user-manual/content-management
  Redirect 301 /examples/dynamic-templates /user-manual/content-management
  Redirect 301 /examples/images /
  Redirect 301 /examples/incremental-variables /
  Redirect 301 /examples/sample-site-structure /user-manual/content-management
  Redirect 301 /quick-start/default /quick-start
  Redirect 301 /user-manual/customize-site-design /user-manual/design-and-layout
  Redirect 301 /user-manual/default /user-manual
  Redirect 301 /user-manual/dynamic-content /
  Redirect 301 /user-manual/generate-site /user-manual/site-generation
  Redirect 301 /user-manual/managing-content /user-manual/content-management
  Redirect 301 /user-manual/pextile-markup-reference /
  Redirect 301 /user-manual/site-configuration /user-manual/site-generation
  Redirect 301 /user-manual/sitemap.xml-and-robots.txt /user-manual/site-generation
  Redirect 301 /user-manual/site-navigation /user-manual/content-management
  Redirect 301 /user-manual/web-server-setup /user-manual/web-server-tips
  # End Old pagegen v0.8 site redirects


  RewriteCond (robots|sitemap).txt.gz -f
  RewriteRule ^.*(robots|sitemap)\.txt$ /$1.txt.gz [NC,L]

  # There will always be html, css, js or txt version of file
  # If file is large enough there will exist a .gz version
  # If gz version exists and client accepts gzip content send it
  # else send regular

  # Serve gzipped if exists
  RewriteCond %{HTTP:Accept-Encoding} gzip
  RewriteCond %{REQUEST_FILENAME}.(txt|css|js).gz -f
  RewriteRule ^(.*)\.(txt|css|js)$ $1.$2.gz [NC,L]

  # If directory show gzipped index file
  RewriteCond %{HTTP:Accept-Encoding} gzip
  RewriteCond %{REQUEST_FILENAME} -d
  RewriteCond %{REQUEST_FILENAME}/index.html.gz -f
  RewriteRule ^(.*)$ $1/index.html.gz [NC,L]

  # If directory show index file (without .html)
  RewriteCond %{HTTP:Accept-Encoding} !gzip
  RewriteCond %{REQUEST_FILENAME} -d
  RewriteCond %{REQUEST_FILENAME}/index.html -f
  RewriteRule ^(.*)$ $1/index.html [NC,L]

  # Serve gzip if available and supported (without .html)
  RewriteCond %{HTTP:Accept-Encoding} gzip
  RewriteCond %{REQUEST_FILENAME}.html.gz -f
  RewriteRule ^(.*)$ $1.html.gz [NC,L]

  # Serve ungziped if available (without .html)
  RewriteCond %{REQUEST_FILENAME}.html -f
  RewriteRule ^(.*)$ $1.html [NC,L]

</IfModule>

' | sed 's/^\ *// ; /^#/d ; /^$/d' > "$site_dir/.htaccess"

  if [ "$env" = "stage" ]; then
    echo -e "User-agent: *\nDisallow: /" > "$site_dir/robots.txt"
  else
    # Prod we want to allow everything
    echo -e "User-agent: *\nAllow: /" > "$site_dir/robots.txt"
  fi

  chmod_dirs="$(find "$site_dir" -type d | sed "s#^$site_dir#$prod_target_dir# ; s/^/chmod 755\ /")"
  chmod_files="$(find "$site_dir" -type f | sed "s#^$site_dir#$prod_target_dir# ; s/^/chmod 644\ /")"

  # NB! TLS at fastline is broken, so need "set ssl:verify-certificate no" in ~/.lftp/rc
  lftp -f /dev/stdin <<EOFFTP
open $prod_host
user $prod_user $prod_pass
lcd $site_dir
mirror --reverse --delete $site_dir $prod_target_dir
$chmod_dirs
$chmod_files
bye
EOFFTP

  # Check links
  echo "Press [ENTER] to check links on new site, any thing else skips:"
  read check_links
  if [ "$check_links" = "" ]; then
    link_log="/tmp/linkchecker.csv"
    if [ "$env" = "stage" ]; then
      pass="-urice -p "
    fi
    linkchecker -ocsv "$pass"$url | sed '/^#/d ; /^mailto:pagegen@phnd.net/d ; /^urlname/d' > "$link_log"
    if [ -s "$link_log" ]; then
      localc "$link_log"
    fi
  fi

elif [ "$env" = "test" ]; then
  $pagegen --generate --config "$test_conf"

  # Replace js.gz and css.gz extensions
  find "$site_dir" -name '*.html' -type f -exec sed -i 's/\.\(js\|css\)\.gz"/.\1"/g' {} \;

else
  echo "Error Unknown environment '$env'" 2>&1
  exit 1
fi


echo "Deployment to '$env' complete"
